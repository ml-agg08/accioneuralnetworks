{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch #for creating tensor objects, backprop etc\n",
        "import torch.nn.functional as F #for one_hot"
      ],
      "metadata": {
        "id": "_L_w2XSn1UM8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jyZRUEOB0oZq"
      },
      "outputs": [],
      "source": [
        "word = [\n",
        "    \"aarav\", \"vivaan\", \"aditya\", \"vihaan\", \"ishaan\", \"arjun\", \"sai\", \"ayaan\", \"krishna\", \"rohan\",\n",
        "    \"reyansh\", \"shiv\", \"mohit\", \"karthik\", \"lakshman\", \"siddharth\", \"manish\", \"vishal\", \"vivek\", \"rahul\",\n",
        "    \"manav\", \"nikhil\", \"kunal\", \"anish\", \"yash\", \"abhinav\", \"pranav\", \"amit\", \"gaurav\", \"ravi\",\n",
        "    \"raj\", \"surya\", \"harsh\", \"tushar\", \"akash\", \"parth\", \"raghav\", \"ramesh\", \"ankit\", \"suresh\",\n",
        "    \"pritam\", \"prem\", \"himesh\", \"ashwin\", \"dhruv\", \"sandeep\", \"vikas\", \"ajay\", \"anil\", \"madhav\",\n",
        "    \"deepak\", \"bhuvan\", \"ashok\", \"ram\", \"shivansh\", \"nitin\", \"saurabh\", \"udit\", \"shaurya\", \"manoj\",\n",
        "    \"chirag\", \"kiran\", \"amitabh\", \"nashit\", \"siddhi\", \"ritika\", \"ananya\", \"priya\", \"aishwarya\", \"sneha\",\n",
        "    \"radhika\", \"meera\", \"swati\", \"pooja\", \"shruti\", \"simran\", \"nisha\", \"sanya\", \"kavya\", \"madhuri\",\n",
        "    \"neha\", \"jaya\", \"mitali\", \"sonali\", \"laxmi\", \"vidya\", \"komal\", \"shalini\", \"tanu\", \"shreya\",\n",
        "    \"nupur\", \"isha\", \"rupa\", \"divya\", \"ritu\", \"vandana\", \"pragya\", \"suman\", \"deepika\", \"manju\",\n",
        "    \"shweta\", \"vaishnavi\", \"parul\", \"gayatri\", \"aarti\", \"tanvi\", \"chhavi\", \"anju\", \"tanisha\", \"sakshi\",\n",
        "    \"simran\", \"sonal\", \"ravina\", \"meenal\", \"aarti\", \"shivani\", \"ankita\", \"kiran\", \"yamini\", \"sonalika\"\n",
        "]\n",
        "\n",
        "#A list of strings; chatgpt generated these kerala origin names to train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "chars=list(string.ascii_lowercase)\n",
        "stoi={s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos={i+1:s for i,s in enumerate(chars)}\n",
        "itos[0]=\".\"\n",
        "\n",
        "#since indexing is based on integers from 0 to 1,2,3.... we map each alphabet to an integer in that order itself"
      ],
      "metadata": {
        "id": "4ZdnRtKP0vJA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "xi=[]\n",
        "y=[]\n",
        "yi=[]\n",
        "for w in word:\n",
        "  w='.'+w+'.'\n",
        "  for i in zip(w,w[1:]):\n",
        "    x.append(i[0])\n",
        "    xi.append(stoi[i[0]])\n",
        "    y.append(i[1])\n",
        "    yi.append(stoi[i[1]])\n",
        "\n",
        "#using zip we create bigraphs and thus generating i/p and o/p labels"
      ],
      "metadata": {
        "id": "DPxKX8Yv1J1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xi=torch.tensor(xi)\n",
        "yi=torch.tensor(yi)\n",
        "#creating tensor objects"
      ],
      "metadata": {
        "id": "NuBdx6SZ1Oux"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xi, num_classes=27).float() #for more efficient working of model, we use one_hat for classes"
      ],
      "metadata": {
        "id": "EULWHPfE1WKM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27),requires_grad=True) #since its a single layer nn with 27 neruons we need a 27x27 weight matrix"
      ],
      "metadata": {
        "id": "yj3OtdUl1Zcz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forward pass matrix multiplication (we use @ for product)\n",
        "logits=xenc@W\n",
        "counts=logits.exp()\n",
        "probs=counts/counts.sum(dim=1,keepdim=True)\n",
        "probs.shape\n",
        "\n",
        "#here we consider cross entropy loss, basically sum of negative logs of each predicted probability values corresponding to actual labels (we already have them for training set)\n",
        "nlls=torch.zeros(len(yi))\n",
        "j=0\n",
        "for i in yi:\n",
        "  loss=torch.log(probs[j,i])\n",
        "  nlls[j]=-loss\n",
        "  j+=1\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())\n",
        "LOSS=nlls.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tj6g_181bDd",
        "outputId": "11c3c936-4c30-460c-900a-b448b5a09dd1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "average negative log likelihood, i.e. loss = 3.8396403789520264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad=None\n",
        "LOSS.backward()\n",
        "#backprop to calculate gradients of each weights like how they affect the final loss"
      ],
      "metadata": {
        "id": "Cl0qkIi31dWw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conducting various epochs and using manual gradient descent to converge to min loss and get corresponding wieghts\n",
        "alpha=1\n",
        "for i in range(50):\n",
        "  W.data+=-alpha*W.grad\n",
        "\n",
        "  #forward pass\n",
        "  logits=xenc@W\n",
        "  counts=logits.exp()\n",
        "  probs=counts/counts.sum(dim=1,keepdim=True)\n",
        "  probs.shape\n",
        "\n",
        "  nlls=torch.zeros(len(yi))\n",
        "  j=0\n",
        "  for i in yi:\n",
        "    loss=torch.log(probs[j,i])\n",
        "    nlls[j]=-loss\n",
        "    j+=1\n",
        "\n",
        "  print('=========')\n",
        "  print('average negative log likelihood, i.e. loss =', nlls.mean().item()+0.01*(W**2).mean())\n",
        "  LOSS=nlls.mean()+0.01*(W**2).mean()"
      ],
      "metadata": {
        "id": "ybv8BCk51iZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28fe98f5-9d23-4d17-8195-53538d7cd24e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7222, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7191, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7161, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7133, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7106, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7081, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7057, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7035, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7014, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6995, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6977, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6960, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6945, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6931, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6919, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6908, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6899, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6890, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6884, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6878, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6874, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6872, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6870, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6870, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6872, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6874, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6878, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6884, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6890, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6898, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6907, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6918, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6929, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6942, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6956, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6971, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.6988, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7006, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7024, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7044, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7066, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7088, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7111, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7136, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7161, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7188, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7216, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7245, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7274, grad_fn=<AddBackward0>)\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = tensor(2.7305, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for i in range(30):\n",
        "  out =[]\n",
        "  ix=0\n",
        "  while True:\n",
        "    inputencode=F.one_hot(torch.tensor([ix]),num_classes=27).float()\n",
        "    logits=inputencode@W\n",
        "    counts=logits.exp()\n",
        "    p=counts/counts.sum(1,keepdims=True)\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(out)\n",
        "\n",
        "  #testing yayyy !!\n"
      ],
      "metadata": {
        "id": "uqntSCrV1mZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c919e7-e3b8-4c07-ddc0-4165e082c972"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', '.']\n",
            "['n', 'i', 'd', 'v', '.']\n",
            "['s', 'h', 'i', '.']\n",
            "['s', 'h', 'a', '.']\n",
            "['p', '.']\n",
            "['s', 'h', 'a', 'n', 'w', 'o', 'c', 'n', 'a', '.']\n",
            "['s', 'h', 'i', '.']\n",
            "['s', 'h', 't', 'o', 'h', 'i', 't', 'u', 's', 'h', 'i', '.']\n",
            "['s', 'h', '.']\n",
            "['s', 'h', 'a', 'n', 'a', 'n', 'u', 'z', 'i', '.']\n",
            "['s', 'h', '.']\n",
            "['a', 'n', 'a', 'n', '.']\n",
            "['d', 'b', 'd', 'a', 'n', 'i', 'r', 'w', 'i', '.']\n",
            "['s', 'h', '.']\n",
            "['s', 'h', 'i', '.']\n",
            "['a', 'n', 'a', 'n', '.']\n",
            "['a', '.']\n",
            "['s', 'h', '.']\n",
            "['s', 'h', 'v', 't', 'u', 'm', 't', 'r', 'a', 'n', '.']\n",
            "['s', 'h', 'u', 'm', 'j', 'm', 'p', 'p', 'p', 'a', 's', 'h', 'i', '.']\n",
            "['a', 'n', 'u', 'a', 'n', 'i', '.']\n",
            "['s', 'o', 'r', 'a', '.']\n",
            "['y', 'a', '.']\n",
            "['s', 'h', 'a', 'n', 'a', 'n', '.']\n",
            "['a', 'n', 'a', 'n', 'i', '.']\n",
            "['s', 'h', 'i', 'm', 'o', 'i', '.']\n",
            "['m', 'w', 'y', 'f', 'v', 'n', '.']\n",
            "['a', 'n', 'a', 'n', 's', 'n', 'h', 'a', 'v', 'j', 'i', 't', 's', 'h', 'a', '.']\n",
            "['s', 'h', 'a', 'd', 'g', 'o', 'n', 'f', 'm', 'p', 'a', 'n', 'a', 'n', 'i', '.']\n",
            "['s', 'h', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwZ1wC1n2gND"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}